# =============================================================================
# PostgreSQL Database
# =============================================================================
POSTGRES_USER=postgres
POSTGRES_PASSWORD=change-this-postgres-admin-password

# Database credentials (used by init-db.sh and applications)
LEAKNOTE_DB_PASSWORD=change-this-leaknote-password

# =============================================================================
# Telegram Bot Configuration
# =============================================================================
# Create bot with @BotFather and get token
# Example: 7123456789:AAHdqTcvCH1vGWJxfSeofSAs0K5PALDsaw
TELEGRAM_BOT_TOKEN=your-bot-token-from-botfather

# Your Telegram user ID (get from @userinfobot)
# Example: 123456789
# This is the only user who can interact with the bot
TELEGRAM_OWNER_ID=your-telegram-user-id

# =============================================================================
# LLM Configuration
# =============================================================================
# Both LLMs use the same configuration pattern:
#   - PROVIDER: openai | anthropic
#   - API_URL: The API endpoint
#   - API_KEY: Your API key
#   - MODEL: The model identifier
#
# The "openai" provider works with any OpenAI-compatible API:
#   - OpenAI:     https://api.openai.com/v1
#   - Ollama:     http://localhost:11434/v1
#   - OpenRouter: https://openrouter.ai/api/v1
#   - Together:   https://api.together.xyz/v1
#   - Groq:       https://api.groq.com/openai/v1
#   - Z.AI:       https://api.z.ai/v1
#   - vLLM:       http://localhost:8000/v1
#   - LiteLLM:    http://localhost:4000/v1

# -----------------------------------------------------------------------------
# Classification LLM (cheap, fast - runs on every capture)
# -----------------------------------------------------------------------------
CLASSIFY_PROVIDER=openai
CLASSIFY_API_URL=https://api.z.ai/v1
CLASSIFY_API_KEY=your-classify-api-key
CLASSIFY_MODEL=glm-4

# Examples:
#
# Ollama (local, free):
#   CLASSIFY_PROVIDER=openai
#   CLASSIFY_API_URL=http://localhost:11434/v1
#   CLASSIFY_API_KEY=ollama
#   CLASSIFY_MODEL=llama3
#
# OpenRouter:
#   CLASSIFY_PROVIDER=openai
#   CLASSIFY_API_URL=https://openrouter.ai/api/v1
#   CLASSIFY_API_KEY=your-openrouter-key
#   CLASSIFY_MODEL=meta-llama/llama-3-8b-instruct
#
# Groq (fast):
#   CLASSIFY_PROVIDER=openai
#   CLASSIFY_API_URL=https://api.groq.com/openai/v1
#   CLASSIFY_API_KEY=your-groq-key
#   CLASSIFY_MODEL=llama-3.1-8b-instant

# -----------------------------------------------------------------------------
# Summary LLM (quality matters - digests, reviews, retrieval)
# -----------------------------------------------------------------------------
SUMMARY_PROVIDER=openai
SUMMARY_API_URL=https://openrouter.ai/api/v1
SUMMARY_API_KEY=your-openrouter-key
SUMMARY_MODEL=anthropic/claude-sonnet-4

# Examples:
#
# Native Anthropic API:
#   SUMMARY_PROVIDER=anthropic
#   SUMMARY_API_URL=https://api.anthropic.com/v1/messages
#   SUMMARY_API_KEY=your-anthropic-key
#   SUMMARY_MODEL=claude-sonnet-4-20250514
#
# OpenRouter (any model):
#   SUMMARY_PROVIDER=openai
#   SUMMARY_API_URL=https://openrouter.ai/api/v1
#   SUMMARY_API_KEY=your-openrouter-key
#   SUMMARY_MODEL=anthropic/claude-sonnet-4
#
# OpenAI:
#   SUMMARY_PROVIDER=openai
#   SUMMARY_API_URL=https://api.openai.com/v1
#   SUMMARY_API_KEY=your-openai-key
#   SUMMARY_MODEL=gpt-4o
#
# Ollama (local):
#   SUMMARY_PROVIDER=openai
#   SUMMARY_API_URL=http://localhost:11434/v1
#   SUMMARY_API_KEY=ollama
#   SUMMARY_MODEL=llama3:70b

# =============================================================================
# Bot Settings
# =============================================================================
# Classification confidence threshold (0.0-1.0)
# Below this, bot asks for clarification instead of auto-filing
CONFIDENCE_THRESHOLD=0.6

# Optional: Per-category thresholds
# CONFIDENCE_THRESHOLD_PEOPLE=0.7
# CONFIDENCE_THRESHOLD_PROJECTS=0.6
# CONFIDENCE_THRESHOLD_IDEAS=0.5
# CONFIDENCE_THRESHOLD_ADMIN=0.65

# =============================================================================
# Admin UI
# =============================================================================
ADMIN_USERNAME=admin
ADMIN_PASSWORD=change-me-secure-password

# =============================================================================
# Memory Layer - Mem0 + Qdrant
# =============================================================================
# Qdrant connection
QDRANT_URL=http://qdrant:6333
# For local development (outside Docker), use: http://localhost:6333

# OpenAI API key for embeddings (text-embedding-3-small)
# Required for semantic search - this is different from the LLM keys below
OPENAI_API_KEY=your-openai-api-key-for-embeddings

# Memory LLM (for LangGraph orchestration, insights, reasoning)
# This can use a different provider/model than the embeddings
MEMORY_PROVIDER=openai
MEMORY_API_URL=https://api.openai.com/v1
MEMORY_API_KEY=your-openai-api-key-for-llm
MEMORY_MODEL=gpt-4o

# Collection names in Qdrant
MEM0_COLLECTION=leaknote_memories

# Memory settings
MEMORY_RETRIEVAL_LIMIT=5  # Number of memories to retrieve for context
MEMORY_CONFIDENCE_THRESHOLD=0.7  # Minimum similarity for memory matches
